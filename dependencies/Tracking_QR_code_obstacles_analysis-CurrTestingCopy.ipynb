{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade opencv-python\n",
    "#!pip install opencv-python numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from shapely.geometry import LineString\n",
    "from shapely.geometry import Point\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "from shapely.geometry import LineString\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Green_square(image, min_blue, min_green, min_red, max_blue, max_green, max_red, kernel_size=5):\n",
    "    \n",
    "    # Taking a matrix of size 5 as the kernel \n",
    "    kernel = np.ones((5, 5), np.uint8) \n",
    "    \n",
    "     # HSV (Hue, Saturation, Value): Separates the color information from the brightness information, making it robust to changes in lighting conditions\n",
    "    hsv_frame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #getting the mask image from the HSV image using threshold values\n",
    "    mask = cv2.inRange(hsv_frame, (min_blue, min_green, min_red), (max_blue, max_green, max_red))\n",
    "    mask_dilation = cv2.dilate(mask, kernel, iterations=1)\n",
    "    mask_erosion = cv2.erode(mask_dilation, kernel, iterations=1) \n",
    "    \n",
    "    # Display the image using matplotlib\n",
    "    #plt.imshow(mask_erosion)\n",
    "    #plt.title(\"mask\")\n",
    "    #plt.axis('off')  # Turn off axis labels\n",
    "    #plt.show()\n",
    "    \n",
    "    return mask_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, min_blue, min_green, min_red, max_blue, max_green, max_red, kernel_size=5):\n",
    "    lower_threshold = 100\n",
    "    upper_threshold = 150\n",
    "    aperture_size = 7\n",
    "    kernel = np.ones((5, 5), np.uint8) \n",
    "    \n",
    "    # HSV (Hue, Saturation, Value): Separates the color information from the brightness information, making it robust to changes in lighting conditions\n",
    "    hsv_frame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #getting the mask image from the HSV image using threshold values\n",
    "    mask = cv2.inRange(hsv_frame, (min_blue, min_green, min_red), (max_blue, max_green, max_red))\n",
    "    mask_dilation = cv2.dilate(mask, kernel, iterations=1)\n",
    "    mask_erosion = cv2.erode(mask_dilation, kernel, iterations=1) \n",
    "    inverted_image = cv2.bitwise_not(mask_erosion)\n",
    "    med_img   = cv2.medianBlur(inverted_image,kernel_size)\n",
    "    canny_img = cv2.Canny(med_img, lower_threshold, upper_threshold, apertureSize=aperture_size, L2gradient=True)\n",
    "    dilated_edges = cv2.dilate(canny_img, kernel, iterations=1)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    #plt.imshow(mask_erosion)\n",
    "    #plt.title(\"mask\")\n",
    "    #plt.axis('off')  # Turn off axis labels\n",
    "    #plt.show()\n",
    "    \n",
    "    return dilated_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projecting image to top view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/perspective-transformation-python-opencv/\n",
    "# https://note.nkmk.me/en/python-opencv-qrcode/\n",
    "# https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html  \n",
    "# https://theailearner.com/tag/cv2-minarearect/\n",
    "\n",
    "def perspective_transformation(image):\n",
    "        \n",
    "    # Destination points for the matrix transformation\n",
    "    #dest_corners =np.float32([(width, height), (0, height), (width, 0), (0, 0)])\n",
    "    height, width, _ = image.shape\n",
    "    dest_corners = np.float32([(0, height), (width, height), (0, 0), (width, 0)])\n",
    "    \n",
    "    # Initialize a list to store the centers of the detected objects\n",
    "    centers = []\n",
    "    \n",
    "    # Mask values of the object to be detected\n",
    "    (min_blue, min_green, min_red) = (19, 0, 0)\n",
    "    (max_blue, max_green, max_red) = (80, 255, 132)\n",
    "\n",
    "    processed_mask = process_Green_square(image, min_blue, min_green, min_red, max_blue, max_green, max_red)\n",
    "    \n",
    "    #extracting the contours of the object\n",
    "    contours,_ = cv2.findContours(processed_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    #sorting the contour based of area\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    # Take the top 4 contours\n",
    "    top_contours = contours[:4]\n",
    "\n",
    "    #print('number of contours', len(top_contours))\n",
    "\n",
    "    # Extract the 4 biggest contours wich are not having the same center\n",
    "    for contour in top_contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        center = (x + w // 2, y + h // 2)\n",
    "\n",
    "        # Check if the center is not close to any existing centers\n",
    "        if all(np.linalg.norm(np.array(center) - np.array(existing_center)) > 50 for existing_center in centers):\n",
    "            centers.append(center)\n",
    "            cv2.rectangle(image, (x - 15, y - 15), (x + w + 15, y + h + 15), (0, 255, 0), 4)\n",
    "    \n",
    "    if len(centers) == 4:\n",
    "        center_points = np.float32(centers).reshape(-1, 1, 2)\n",
    "        transformation_matrix = cv2.getPerspectiveTransform(center_points, dest_corners)\n",
    "        return transformation_matrix\n",
    "    else:\n",
    "    # Return the initial image if not enough contours are detected\n",
    "        transformation_matrix = None\n",
    "        return transformation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to adjsut threshold (not in the final submition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty function\n",
    "def doNothing(x):\n",
    "    pass\n",
    "\n",
    "def find_thresh(image):\n",
    "    #creating a resizable window named Track Bars\n",
    "    cv2.namedWindow('Track Bars', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    #creating track bars for gathering threshold values of red green and blue\n",
    "    cv2.createTrackbar('min_blue', 'Track Bars', 0, 255, doNothing)\n",
    "    cv2.createTrackbar('min_green', 'Track Bars', 0, 255, doNothing)\n",
    "    cv2.createTrackbar('min_red', 'Track Bars', 0, 255, doNothing)\n",
    "\n",
    "    cv2.createTrackbar('max_blue', 'Track Bars', 0, 255, doNothing)\n",
    "    cv2.createTrackbar('max_green', 'Track Bars', 0, 255, doNothing)\n",
    "    cv2.createTrackbar('max_red', 'Track Bars', 0, 255, doNothing)\n",
    "\n",
    "    resized_image = cv2.resize(image,(800, 626))\n",
    "    #converting into HSV color model\n",
    "    hsv_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #showing both resized and hsv image in named windows\n",
    "    #cv2.imshow('Base Image', resized_image)\n",
    "    #cv2.imshow('HSV Image', hsv_image)\n",
    "\n",
    "\n",
    "    #creating a loop to get the feedback of the changes in trackbars\n",
    "    while True:\n",
    "        #reading the trackbar values for thresholds\n",
    "        min_blue = cv2.getTrackbarPos('min_blue', 'Track Bars')\n",
    "        min_green = cv2.getTrackbarPos('min_green', 'Track Bars')\n",
    "        min_red = cv2.getTrackbarPos('min_red', 'Track Bars')\n",
    "\n",
    "        max_blue = cv2.getTrackbarPos('max_blue', 'Track Bars')\n",
    "        max_green = cv2.getTrackbarPos('max_green', 'Track Bars')\n",
    "        max_red = cv2.getTrackbarPos('max_red', 'Track Bars')\n",
    "\n",
    "        #using inrange function to turn on the image pixels where object threshold is matched\n",
    "        mask = cv2.inRange(hsv_image, (min_blue, min_green, min_red), (max_blue, max_green, max_red))\n",
    "        #showing the mask image\n",
    "        cv2.imshow('Mask Image', mask)\n",
    "        # checking if q key is pressed to break out of loop\n",
    "        key = cv2.waitKey(25)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    #printing the threshold values for usage in detection application\n",
    "    print(f'min_blue {min_blue}  min_green {min_green} min_red {min_red}')\n",
    "    print(f'max_blue {max_blue}  max_green {max_green} max_red {max_red}')\n",
    "    #destroying all windows\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing each vertex in different colors (not used in the final submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vertex_circles(image, points):\n",
    "    # Ensure there is at least one set of vertices\n",
    "    if len(points) < 1 or len(points[0]) < 3:\n",
    "        raise ValueError(\"The function expects at least one set of three vertices.\")\n",
    "\n",
    "    # Extract vertices from the array\n",
    "    vertices_np = np.array(points[0], dtype=np.int32)\n",
    "\n",
    "    # Define colors for each vertex\n",
    "    colors = [\n",
    "        (0, 0, 255),  # Red for the first vertex\n",
    "        (0, 255, 0),  # Green for the second vertex\n",
    "        (255, 0, 0),  # Blue for the third vertex\n",
    "        (255, 255, 0),  # Yellow for the fourth vertex (and so on...)\n",
    "    ]  # BGR format\n",
    "\n",
    "    # Draw circles around each vertex with different colors\n",
    "    for i, vertex in enumerate(vertices_np):\n",
    "        color = colors[i % len(colors)]  # Cycle through colors if there are more vertices\n",
    "        cv2.circle(image, tuple(vertex), 5, color, -1)  # -1 fills the circle\n",
    "\n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(\"Image with Vertex Circles and Polyline\")\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angle of the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orientation_angle(points):\n",
    "    \n",
    "    points_np = np.array(points[0], dtype=np.float32)\n",
    "\n",
    "    # Calculate the centroid (center) of the robot\n",
    "    robot_center = np.mean(points_np, axis=0)\n",
    "\n",
    "    # Choose one vertex as a reference (e.g., the first vertex)\n",
    "    right_front = points_np[0]\n",
    "    left_front = points_np[3]\n",
    "    center_front = ((right_front[0] + left_front[0]) / 2, (right_front[1] + left_front[1]) / 2)\n",
    "\n",
    "    # Calculate the vector from the centroid to the reference vertex\n",
    "    vector_to_reference = center_front - robot_center\n",
    "\n",
    "    # Calculate the orientation angle in degrees in the range of -180 to 180 degrees\n",
    "    angle = (np.arctan2(vector_to_reference[1], vector_to_reference[0]) * 180 / np.pi + 180) % 360 - 180\n",
    "\n",
    "    return angle, robot_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mean angle over a window of frames\n",
    "def calculate_mean_angle(angle_list):\n",
    "    return sum(angle_list) / len(angle_list) if len(angle_list) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the contours found to detect the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectShape(cnt):          #Function to determine type of polygon on basis of number of sides\n",
    "    shape = 'unknown' \n",
    "    peri=cv2.arcLength(cnt,True) \n",
    "    vertices = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "    sides = len(vertices)\n",
    "    #print('sides', sides)\n",
    "    if (sides == 3): \n",
    "        shape='triangle' \n",
    "    elif(sides==8): \n",
    "        shape='octagon' \n",
    "    else:\n",
    "        shape='circle' \n",
    "    return shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS: a contour, and minimum distance need to scale the contour\n",
    "def scale_contour(original_contour, desired_min_distance):\n",
    "    # Get the bounding rectangle around the shape\n",
    "    x, y, w, h = cv2.boundingRect(original_contour)\n",
    "\n",
    "    # Calculate the center of the bounding rectangle\n",
    "    center = ((x + w // 2), (y + h // 2))\n",
    "    \n",
    "    scaled_adequate = False\n",
    "    scale_factor = 1.3;\n",
    "    \n",
    "    while (not scaled_adequate):\n",
    "        # Scale each point of the contour relative to the center\n",
    "        scaled_contour = np.array([[(point[0][0] - center[0]) * scale_factor + center[0],\n",
    "                                (point[0][1] - center[1]) * scale_factor + center[1]]\n",
    "                               for point in original_contour], dtype=np.int32)\n",
    "        #print(scaled_contour)\n",
    "        # checking if contour is scaled enough\n",
    "        min_distance = float('inf')\n",
    "\n",
    "        #print(original_contour)\n",
    "        for point in scaled_contour:\n",
    "            point = tuple(float(coord) for coord in point)\n",
    "            distance = cv2.pointPolygonTest(original_contour, point, True)\n",
    "            min_distance = min(min_distance, abs(distance))\n",
    "        #print(min_distance)\n",
    "        if (min_distance < desired_min_distance):\n",
    "            scale_factor += 0.01\n",
    "            print(scale_factor)\n",
    "        else:\n",
    "            scaled_adequate = True\n",
    "            print(\"adequate\")\n",
    "    \n",
    "    return scaled_contour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the obstacles in the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_obstacles(contours):\n",
    "    triangle_vertices = []  # List to store vertices for each triangle\n",
    "    triangle_edges = []  # List to store lines for each triangle\n",
    "\n",
    "    for cnt in contours:\n",
    "        shape = detectShape(cnt)\n",
    "        \n",
    "        cnt = scale_contour(cnt, minimum_distance)\n",
    "        \n",
    "        if shape == 'triangle':\n",
    "            print('shape',shape)\n",
    "            vertices = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)\n",
    "            triangle = []  # Store vertices for each triangle\n",
    "            edges = []  # Store lines for each triangle\n",
    "            \n",
    "            for i, vertex in enumerate(vertices):\n",
    "                x, y = vertex[0]\n",
    "                triangle.append((x, y))\n",
    "\n",
    "                # Calculate the index of the next vertex in the list (wrapping around to the first vertex if it's the last one)\n",
    "                next_index = 0 if i == len(vertices) - 1 else i + 1\n",
    "                next_vertex = vertices[next_index][0]\n",
    "\n",
    "                # Append the current edge to the list of edges\n",
    "                edges.append(((x, y), (next_vertex[0], next_vertex[1])))\n",
    "\n",
    "            triangle_vertices.append(triangle)  # Append the vertices to the list\n",
    "            triangle_edges.append(edges)  # Append the edges to the list\n",
    "    return triangle_vertices, triangle_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identifying the Goal in the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_goal(contours):\n",
    "\n",
    "    goal_center = None\n",
    "    \n",
    "    for cnt in contours:\n",
    "        shape = detectShape(cnt)\n",
    "        print('shape',shape)\n",
    "        if shape == 'octagon':\n",
    "            # Store circle information\n",
    "            (goal_center, radius) = cv2.minEnclosingCircle(cnt)\n",
    "            goal_center = (int(goal_center[0]), int(goal_center[1]))\n",
    "            radius = int(radius)\n",
    "\n",
    "    return goal_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if direct lines are possible between vertices taking in account the obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_intersection(vertex1, vertex2, triangle1_edges, triangle2_edges):\n",
    "    line = LineString([vertex1, vertex2])\n",
    "    #print('line1', line)\n",
    "    for edge in triangle1_edges:\n",
    "        for i in range(len(edge)):\n",
    "            if i != len(edge) - 1:\n",
    "                edge1 = LineString([edge[i], edge[i + 1]])\n",
    "            else:\n",
    "                edge1 = LineString([edge[i], edge[0]])\n",
    "\n",
    "            if (line.coords[0] in edge1.coords) or (line.coords[1] in edge1.coords):\n",
    "                #print('The line shares a common point with triangle 1 edge:', edge1)\n",
    "                break  # Disregard connection if the same vertex is part of both lines\n",
    "\n",
    "            elif line.intersects(edge1):\n",
    "                #print('Intersection found with triangle 1 edge:', edge1)\n",
    "                return True  # If an intersection is detected, return True\n",
    "\n",
    "    for edge in triangle2_edges:\n",
    "        for i in range(len(edge)):\n",
    "            if i != len(edge) - 1:\n",
    "                edge2 = LineString([edge[i], edge[i + 1]])\n",
    "            else:\n",
    "                edge2 = LineString([edge[i], edge[0]])\n",
    "\n",
    "            if (line.coords[0] in edge2.coords) or (line.coords[1] in edge2.coords):\n",
    "                #print('The line shares a common point with triangle 2 edge:', edge2)\n",
    "                break  # Disregard connection if the same vertex is part of both lines\n",
    "\n",
    "            elif line.intersects(edge2):\n",
    "                #print('Intersection found with triangle 2 edge:', edge2)\n",
    "                return True  # If an intersection is detected, return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating adjancy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(triangle_vertices, triangle_edges, Xcent, Ycent, Xrob_center, Yrob_center):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for i, triangle1 in enumerate(triangle_vertices):\n",
    "        for j, triangle2 in enumerate(triangle_vertices):\n",
    "            if i != j:  # Ensure you're comparing vertices from different triangles\n",
    "                for vertex1 in triangle1:\n",
    "                    for vertex2 in triangle2:\n",
    "                        if vertex1 != vertex2:\n",
    "                            intersection = check_intersection(vertex1, vertex2, triangle_edges[i], triangle_edges[j])\n",
    "                            if not intersection:  # If no intersection, add to the edge if intersection = false add\n",
    "                                G.add_edge(vertex1, vertex2)  # Add edge to the graph\n",
    "                            # Handling the initial position and the goal of the robot\n",
    "                            circle_intersect_v1 = check_intersection(vertex1, (Xcent, Ycent), triangle_edges[i], triangle_edges[j])\n",
    "                            circle_intersect_v2 = check_intersection(vertex2, (Xcent, Ycent), triangle_edges[i], triangle_edges[j])\n",
    "                            robot_intersect_v1 = check_intersection(vertex1, (Xrob_center, Yrob_center), triangle_edges[i], triangle_edges[j])\n",
    "                            robot_intersect_v2 = check_intersection(vertex2, (Xrob_center, Yrob_center), triangle_edges[i], triangle_edges[j])\n",
    "\n",
    "                            if not circle_intersect_v1:\n",
    "                                G.add_edge(vertex1, (Xcent, Ycent))\n",
    "                            if not circle_intersect_v2:\n",
    "                                G.add_edge(vertex2, (Xcent, Ycent))\n",
    "                            if not robot_intersect_v1:\n",
    "                                G.add_edge(vertex1, (Xrob_center, Yrob_center))\n",
    "                            if not robot_intersect_v2:\n",
    "                                G.add_edge(vertex2, (Xrob_center, Yrob_center))\n",
    "\n",
    "    # Iterate through each triangle\n",
    "    for i, triangle_edge in enumerate(triangle_edges):\n",
    "        for edge in triangle_edge:\n",
    "            G.add_edge(edge[0], edge[1])  # Add each edge to the graph\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria for shortest path is the distance between vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_euclidean_distances(G):\n",
    "    euclidean_distances = {}\n",
    "    \n",
    "    for u, v in G.edges:\n",
    "        # Extract coordinates of the vertices (u and v)\n",
    "        x1, y1 = u\n",
    "        x2, y2 = v\n",
    "\n",
    "        # Calculate Euclidean distance between the vertices\n",
    "        distance = ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5\n",
    "\n",
    "        # Store the calculated Euclidean distance in the dictionary\n",
    "        euclidean_distances[(u, v)] = distance\n",
    "\n",
    "    return euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process global obstacles and Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_background(image):\n",
    "    \n",
    "    # Scale_factor\n",
    "    \n",
    "    # Defining the the RGB threshold values for the obstacles\n",
    "    (min_blue_obst, min_green_obst, min_red_obst) = (0, 16, 23)\n",
    "    (max_blue_obst, max_green_obst, max_red_obst) = (69, 175, 57)\n",
    "    \n",
    "    # Defining the the RGB threshold values for the goal destination\n",
    "    (min_blue_goal, min_green_goal, min_red_goal) = (40, 0, 0)\n",
    "    (max_blue_goal, max_green_goal, max_red_goal) = (219, 222, 255)\n",
    "    \n",
    "    # Processing the obstacles to find the vertices and edges\n",
    "    processed_obstacles = process_image(image, min_blue_obst, min_green_obst, min_red_obst, max_blue_obst, max_green_obst, max_red_obst)  \n",
    "    (obstacle_contours, _) = cv2.findContours(processed_obstacles, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    triangle_vertices, triangle_edges = process_obstacles(obstacle_contours, scalefactor)\n",
    "    \n",
    "    # Processing the goal destination to find the center\n",
    "    processed_goal = process_image(image, min_blue_goal, min_green_goal, min_red_goal, max_blue_goal, max_green_goal, max_red_goal)  \n",
    "    (goal_contours, _) = cv2.findContours(processed_goal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    goal_center = process_goal(goal_contours)\n",
    "    \n",
    "    # Display the processed grayscale mask using matplotlib\n",
    "    #plt.imshow(processed_goal, cmap='gray')\n",
    "    #plt.title(\"goal\")\n",
    "    #plt.axis('off')\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    return triangle_vertices, triangle_edges, goal_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShortestPath Using pyvisgraph\n",
    "Using PyVisGraph library, which creates an visiblity graph and uses Dijkstras algorithm to find the shortest path\n",
    "Source: https://github.com/TaipanRex/pyvisgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS: vertices of obstacles, the robot position, goal position\n",
    "def getShortestPath(shape_vertices, Rob_pos, Goal_pos):\n",
    "    polygons = []\n",
    "    for shape in shape_vertices:\n",
    "        polygon = []\n",
    "        for point in shape:\n",
    "            polygon.append(vg.Point(point[0], point[1]))\n",
    "        polygons.append(polygon)\n",
    "\n",
    "    graph = vg.VisGraph()\n",
    "    graph.build(polygons)\n",
    "\n",
    "    startPosition = vg.Point(Rob_pos[0],Rob_pos[1])\n",
    "    endPosition = vg.Point(Goal_pos[0], Goal_pos[1])\n",
    "\n",
    "    shortestPath = graph.shortest_path(startPosition, endPosition)\n",
    "    print(shortestPath)\n",
    "    return shortestPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrawPath\n",
    "Function visualizes the paths that is generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS: the shortestPath: a vector of vg.Point vertices\n",
    "# shape_vertices: the vertices of expanded shapes\n",
    "# pathImage: the image to draw the path\n",
    "def drawPath(shape_vertices, shortestPath, pathImage):\n",
    "    \n",
    "    for vertices in shape_vertices:\n",
    "        for i, vertex in enumerate(vertices):\n",
    "            x = vertex[0]\n",
    "            y = vertex[1]\n",
    "            cv2.circle(pathImage, (x, y), 5, (255, 0, 0), -1)  \n",
    "    \n",
    "    edgelist = []\n",
    "\n",
    "    for i, node in enumerate(shortestPath[:-1]):\n",
    "        print(shortestPath[i])\n",
    "        edgelist.append((shortestPath[i], shortestPath[i + 1]))\n",
    "        \n",
    "    color = (255, 255, 255)\n",
    "    thickness = 3\n",
    "    for i, edge in enumerate(edgelist):\n",
    "        #print(int(edgelist[i][0].x), int(edgelist[i][0].y))\n",
    "        cv2.line(pathImage, (int(edgelist[i][0].x), int(edgelist[i][0].y)), (int(edgelist[i][1].x), int(edgelist[i][1].y)), color, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shortest_path(triangle_vertices, triangle_edges, goal_center, robot_center):\n",
    "\n",
    "    # Findinf the adjancy matrix used in the A* global shortest path\n",
    "    G = create_graph(triangle_vertices, triangle_edges, goal_center[0], goal_center[1], robot_center[0], robot_center[1])\n",
    "\n",
    "    euclidean_distances = calculate_euclidean_distances(G)\n",
    "\n",
    "    # Draw the graph\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_size=600, font_weight='bold')\n",
    "    # Draw the highlighted vertex of position of robot and goal position  in a different color\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[(goal_center[0], goal_center[1])], node_size=600, node_color='red')\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[(robot_center[0], robot_center[1])], node_size=600, node_color='green')\n",
    "\n",
    "    plt.title('Adjacency Graph with highlighted final destination in red and position of robot in green')\n",
    "    plt.show()\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking of QR code position and angle in the new perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape octagon\n",
      "vertices []\n",
      "edges []\n",
      "goal (458, 293)\n",
      "background found True\n",
      "shape octagon\n",
      "vertices []\n",
      "edges []\n",
      "goal (458, 292)\n",
      "background found True\n",
      "shape octagon\n",
      "vertices []\n",
      "edges []\n",
      "goal (458, 293)\n",
      "background found True\n",
      "shape octagon\n",
      "vertices []\n",
      "edges []\n",
      "goal (458, 293)\n",
      "background found True\n",
      "shape octagon\n",
      "vertices []\n",
      "edges []\n",
      "goal (458, 293)\n",
      "background found True\n",
      "shape triangle\n",
      "shape octagon\n",
      "vertices [[(289, 161), (384, 251), (437, 216)]]\n",
      "edges [[((289, 161), (384, 251)), ((384, 251), (437, 216)), ((437, 216), (289, 161))]]\n",
      "goal (458, 293)\n",
      "background found True\n",
      "shape triangle\n",
      "shape octagon\n",
      "vertices [[(290, 161), (384, 251), (437, 216)]]\n",
      "edges [[((290, 161), (384, 251)), ((384, 251), (437, 216)), ((437, 216), (290, 161))]]\n",
      "goal (458, 293)\n",
      "background found True\n",
      "shape triangle\n",
      "shape octagon\n",
      "vertices [[(288, 162), (382, 251), (437, 216)]]\n",
      "edges [[((288, 162), (382, 251)), ((382, 251), (437, 216)), ((437, 216), (288, 162))]]\n",
      "goal (458, 292)\n",
      "background found True\n",
      "shape triangle\n",
      "shape octagon\n",
      "vertices [[(288, 161), (382, 251), (437, 216)]]\n",
      "edges [[((288, 161), (382, 251)), ((382, 251), (437, 216)), ((437, 216), (288, 161))]]\n",
      "goal (458, 294)\n",
      "background found True\n",
      "shape triangle\n",
      "shape octagon\n",
      "vertices [[(288, 161), (383, 251), (437, 217)]]\n",
      "edges [[((288, 161), (383, 251)), ((383, 251), (437, 217)), ((437, 217), (288, 161))]]\n",
      "goal (458, 292)\n",
      "background found True\n",
      "shape triangle\n",
      "shape triangle\n",
      "shape octagon\n",
      "shape circle\n",
      "vertices [[(287, 161), (383, 251), (437, 216)], [(74, 0), (39, 42), (0, 125)]]\n",
      "edges [[((287, 161), (383, 251)), ((383, 251), (437, 216)), ((437, 216), (287, 161))], [((74, 0), (39, 42)), ((39, 42), (0, 125)), ((0, 125), (74, 0))]]\n",
      "goal (458, 293)\n",
      "background found True\n"
     ]
    }
   ],
   "source": [
    "window_name = 'Tracking QR Code'\n",
    "camera_id = 1 # Try changing with one of these (0,1,2..) because it depends how amny cameras are connected to your PC\n",
    "\n",
    "video_stream = cv2.VideoCapture(camera_id)\n",
    "QR_detector = cv2.QRCodeDetector()\n",
    "\n",
    "angle_window = []  # List to store angles over a window of frames\n",
    "window_size = 5  # calculate the mean over that number of frames\n",
    "\n",
    "transformation_matrix_found = False\n",
    "transformation_matrix = None\n",
    "background_found = False\n",
    "\n",
    "num_obstacles = 0\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not video_stream.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    # Capture a frame from the video stream\n",
    "    image_detected, image = video_stream.read()\n",
    "    #find_thresh(image)\n",
    "    if image_detected:\n",
    "        image_initial = image.copy()\n",
    "        height, width, channels = image.shape\n",
    "        # Apply the new percpective on the frame\n",
    "        if not transformation_matrix_found:\n",
    "            transformation_matrix = perspective_transformation(image)\n",
    "            transformation_matrix_found = True\n",
    "        if transformation_matrix_found:\n",
    "            new_perspective_image = cv2.warpPerspective(image, transformation_matrix, (width, height))\n",
    "        else:\n",
    "            new_perspective_image = image\n",
    "        if not background_found or num_obstacles != 2:\n",
    "            triangle_vertices, triangle_edges, goal_center = process_background(image)\n",
    "            num_obstacles = len(triangle_vertices)\n",
    "            print('vertices',triangle_vertices)\n",
    "            print('edges',triangle_edges)\n",
    "            print('goal',goal_center)\n",
    "            background_found = True\n",
    "            print('background found', background_found)\n",
    "            continue\n",
    "\n",
    "        if background_found:    \n",
    "            # Detect QR codes in the captured frame\n",
    "            QR_detected, points, _ = QR_detector.detectAndDecode(image_initial)\n",
    "\n",
    "            if QR_detected: \n",
    "                points = cv2.perspectiveTransform(points.reshape(-1, 1, 2), transformation_matrix)\n",
    "                points = points.reshape(1, 4, 2)\n",
    "\n",
    "                angle, robot_center = orientation_angle(points)\n",
    "                #print('robot center',robot_center)\n",
    "                #print(f\"Individual Angle: {angle} degrees\")\n",
    "                angle_window.append(angle)\n",
    "                if len(angle_window) == window_size:\n",
    "                    mean_angle = calculate_mean_angle(angle_window)\n",
    "                    #G = find_shortest_path(image, robot_center)\n",
    "                    #print(f\"Mean Angle over {window_size} frames: {mean_angle} degrees\")\n",
    "                    angle_window = []  # Reset the window for the next set of frames\n",
    "\n",
    "                #draw_vertex_circles(img_copy, points)  \n",
    "                color = (0, 255, 0)\n",
    "                new_perspective_image = cv2.polylines(new_perspective_image, [points.astype(int)], isClosed=True, color=color, thickness=8)\n",
    "                #print(points)\n",
    "                if num_obstacles != 0:\n",
    "                    \n",
    "                    for vertices in triangle_vertices:\n",
    "                        for i, vertex in enumerate(vertices):\n",
    "                            x = vertex[0]\n",
    "                            y = vertex[1]\n",
    "                            cv2.circle(new_perspective_image, (x, y), 10, (255, 0, 0), -1) \n",
    "                    #new_perspective_image = cv2.polylines(new_perspective_image, polyTriangle_vertices, isClosed=True, color=color, thickness=8)\n",
    "                \n",
    "                # Display the modified image in the window\n",
    "                cv2.imshow(window_name, new_perspective_image)\n",
    "                #G = find_shortest_path(triangle_vertices, triangle_edges, goal_center, robot_center)\n",
    "\n",
    "    # Exiting the loop when the 'Esc' key is pressed\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "video_stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  green QR circle obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'triangle_vertices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtriangle_vertices\u001b[49m\n\u001b[0;32m      2\u001b[0m polyTriangle_vertices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'triangle_vertices' is not defined"
     ]
    }
   ],
   "source": [
    "triangle_vertices\n",
    "polyTriangle_vertices = np.empty((3, 2))\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        polyTriangle_vertices[i][j] = triangle_vertices[0][i][j].astype(int)\n",
    "        \n",
    "polyTriangle_vertices = cv2.perspectiveTransform(polyTriangle_vertices[0].reshape(-1, 1, 2), transformation_matrix)        \n",
    "print(polyTriangle_vertices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
